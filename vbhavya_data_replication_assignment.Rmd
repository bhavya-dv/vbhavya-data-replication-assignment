---
title: "vbhavya_data_replication"
author: "Bhavya Deepti Vadavalli"
date: "2023-12-03"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Introduction:
### About Hunter-Gatherer Social Networks: 

# Goals of the Project:

# Methodology: 
## Horton Analysis:

## Binford Dataset: 


### Managing the Data:

Upon loading the data set, we see that this is a BIG data set, with a lot of information. We need to first figure out which information is useful to us. In this paper, the authors analyse group sizes at 6 different levels. Which columns contain the relevant information for each Horton order? 

It looks like: 

1. This data set does not contain information at the level of individuals (i.e. Horton order 1)
2. The column titled "famsz" gives us the group sizes at the scale of a family. This corresponds to Horton order 2. 
3. The column titled "group1" gives us the group sizes at the scale of a "dispersed group". This corresponds to Horton order 3.
4. The column titled "group2" gives us the group sizes at the scale of a "aggregated group". This corresponds to Horton order 4.
5. The column titled "group3" gives us the group sizes at the scale of a "periodic aggregations". This corresponds to Horton order 5.
6. The column titled "tlpop" gives us the total population sizes for each HG group. This corresponds to Horton order 6. 

The values above represent the group sizes, however, for our analysis, we also need the frequency of these groups which are given by: 
1. Frequency of individuals, as given by "tlpop". This is for Horton order 1. 
2. Number of families in society, given by "numfam", which represents the famsz/tlpop values. This is for Horton order 2. 
3. Number of group1 units in society, given by "numg1". It is given by tlpop/group1 and represent Horton order 3.
4.Number of group2 units in society, given by "numg2", represents the frequency of dispersed groups. It is given by tlpop/group2. This is for Horton order 4.
5. Number of group3 units in society, given by "numg3". It is given by tlpop/group3 and represents Horton Order 5. 


The documentation for these values was taken from: https://github.com/benmarwick/binford/blob/master/data-raw/LRBcodebook.txt

Let us load in the data, clean the data (if required) and check our sample sizes for each Horton order so that we are good to start replicating tables or figures. 

```{r data_cleaning1.1}
library(curl)

dat <- read.csv(curl("https://raw.githubusercontent.com/bhavya-dv/vbhavya-data-replication-assignment/main/LRB.csv"))
head(dat) #loading in the Binford dataset

length(dat) #There are 507 data points. 

# But this means that there are multiple columns of the same group.  
# Does this matter for our analysis? Yes, because we will be using the geometric mean to summarize the data, rather than arithmetic mean, we must make sure that are sample sizes and values are correct. But let's address that problem separately for each Horton Order


# Creating a data frame with only total population sizes (HO = 6): 
population <- dat$tlpop
length(population) # our N matches the N in Table 1 of Hamilton et al., 2007!

# Creating a data frame with only "group3" (HO = 5): 
gr3 <- dat$group3
gr3 <- na.omit(gr3) 
length(gr3) #interesting, we are getting an N of 216, but Hamilton et al have an N of 213. Are there any duplicates? We will proceed with this. It is possible that Hamilton et al., 2007 removed 3 data points without mentioning it. We don't know. There is no documentation about this either. 

# Creating a data frame with only "group2" (HO = 4): 
gr2 <- dat$group2
gr2 <- na.omit(gr2) 
length(gr2) #We are getting the same N as that in table 1 of Hamilton et al., 2007
 
# Creating a data frame with only "group1" (HO = 3): 
gr1 <- dat$group1
gr1 <- na.omit(gr1) 
length(gr1) #We are getting the same N as that in table 1 of Hamilton et al., 2007

# Creating a data frame with only "famsz" (HO = 2): 
family <- dat$famsz
family <- na.omit(family) 
length(family) # 136, there are some non unique values
family <- unique(family) 
length(family) #Now, We are getting the same n=102 which is not the same as that of table 1 of Hamilton et al., 2007, but we will proceed with this nonetheless.

all_groups_dat <- list(family,gr1,gr2,gr3,population) #a list comprising of all the required data.frames
```
```{r datacleanign1.2}
freq_tlpop <- dat$tlpop

numg3 <- na.omit(dat$numg3)

numg2 <- na.omit(dat$numg2)

numg1 <- na.omit(dat$numg1)

numfam <- na.omit(dat$numfam)

 #some of the sample sizes in Table 1.2 are different from what we get from these data frames. There is no information in the documentation or Hmailton., 2007 about if and which values were removed, but it is likely that some values were removed. We will proceed with sample sizes that we have for now.

all_groups_freq <- list(freq_tlpop,numfam,numg1,numg2,numg3) #a list comprising of all the required data.frames for table 1.2
```


### Table 1 

```{r table1.1}
#creating an empty table where values can be input
table1.1 <- data.frame(matrix(NA, nrow = 6, ncol = 8))
colnames(table1.1) <- c("organisational level group size (g)", "Horton order (ω)", "sample size (n)", "ln mean <ln g>", "s.d", "geometric mean (g-bar)", "95% CI - Lower", "95% CI - upper")
table1.1[,1] <- c("individual", "family","dispersed group","aggregated group","periodic aggregation","poopulation size")
table1.1[,2] <- 1:6
table1.1[,3] <- c("NA", 102,227,297,216,339)

#Okay, now we can start filling in this table with some summary statistics!

#filling in ln means, sd and geometric means
for (i in 1:5) {
  ln_mean <- mean(log(all_groups_dat[[i]]))
  table1.1[i+1,4] <- ln_mean
  table1.1[1,4] <- 0
  
  sd <- sd(log(all_groups_dat[[i]]))
  table1.1[i+1,5] <- sd
  table1.1[1,5] <- NA
  
  geom_mean <- exp(ln_mean)
  table1.1[i+1,6] <- geom_mean
  table1.1[1,6] <- 1
} 

table1.1 #Here, we see that the values are a little bit different that the original paper. But they don't seem different enough to warrant concern, yet. 

#Bootstrapping For CIs (ln_mean) 
for (i in 1:5) {
  ln_dat <- log(all_groups_dat[[i]]) #We will bootstrap with this data 
  ln_mean <- mean(ln_dat)
  boots_ln_dat = ln_dat[sample(1:length(ln_dat), 1000, replace = TRUE)] #resampling with replacement. Creating 1000 samples
  mean_boots <- exp(mean(boots_ln_dat)) #geometric mean for bootsrapped values
  sd_boots <- sd(boots_ln_dat) #sd for bootsrapped values

  #lower - 95% CI
  lower_CI <- mean_boots - qnorm(1 - 0.05/2) * sd_boots #lower CI
  lower_CI
  table1.1[i+1,7] <- lower_CI
  table1.1[1,7] <- NA
  
  #upper - 95% CI
  upper_CI <- mean_boots + qnorm(1 - 0.05/2) * sd_boots #upper CI
  upper_CI
  table1.1[i+1,8] <- upper_CI
  table1.1[1,8] <- NA
}

table1.1 #The CI values actually look quite different from the values in the published table

```
```{r table1.2}
#creating an empty table where values can be input
table1.2 <- data.frame(matrix(NA, nrow = 6, ncol = 8))
colnames(table1.2) <- c("Frequency, N(g)", "Horton order (ω)", "sample size (n)", "ln mean <ln N(g)>", "s.d", "geometric mean (N(g)-bar)", "95% CI - Lower", "95% CI - upper")
table1.2[,1] <- c("individual", "family","dispersed group","aggregated group","periodic aggregation","poopulation size")
table1.2[,2] <- 1:6
table1.2[,3] <- c(339, 216, 297, 227, 128, "NA")

#Okay, now we can start filling in this table with some summary statistics!

#filling in ln means, sd and geometric means
for (i in 1:5) {
  ln_mean <- mean(log(all_groups_freq[[i]]))
  table1.2[i,4] <- ln_mean
  table1.2[6,4] <- 0
  
  sd <- sd(log(all_groups_freq[[i]]))
  table1.2[i,5] <- sd
  table1.2[6,5] <- NA
  
  geom_mean <- exp(ln_mean)
  table1.2[i,6] <- geom_mean
  table1.2[6,6] <- 1
} 

table1.2 #Here, we see that the values are a little bit different that the original paper. But they don't seem different enough to warrant concern, yet. 

#Bootstrapping For CIs (ln_mean) 
for (i in 1:5) {
  ln_dat <- log(all_groups_freq[[i]]) #We will bootstrap with this data 
  ln_mean <- mean(ln_dat)
  boots_ln_dat = ln_dat[sample(1:length(ln_dat), 1000, replace = TRUE)] #resampling with replacement. Creating 1000 samples
  mean_boots <- exp(mean(boots_ln_dat)) #geometric mean for bootsrapped values
  sd_boots <- sd(boots_ln_dat) #sd for bootsrapped values

  #lower - 95% CI
  lower_CI <- mean_boots - qnorm(1 - 0.05/2) * sd_boots #lower CI
  lower_CI
  table1.2[i,7] <- lower_CI
  table1.2[6,7] <- NA
  
  #upper - 95% CI
  upper_CI <- mean_boots + qnorm(1 - 0.05/2) * sd_boots #upper CI
  upper_CI
  table1.2[i,8] <- upper_CI
  table1.2[6,8] <- NA
}

table1.2 #The CI values actually look quite different from the values in the published table, but that is to be expected if we bootstrap the values. 

```

### Assumptions:

