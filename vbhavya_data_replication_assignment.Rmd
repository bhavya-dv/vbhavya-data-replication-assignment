---
title: "vbhavya_data_replication"
author: "Bhavya Deepti Vadavalli"
date: "2023-12-03"
output: 
  prettydoc::html_pretty:
    theme: cayman
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## Introduction:
### Hamilton et al., 2007: 
In this publication, Hamilton et al., use the Binford data set (details given below) to demonstrate that the social network structures of hunter-gatherer groups are self-similar. They use fractal theory to achieve this. But simply put, they show that when the number of groups in each successive organisational level are divided by the number of groups in the previous organizational level, a constant number (~4) is obtained. 

These organisational levels are known as Horton Orders (ranging from 1 to 6). Horton analysis is frequently used to study drainage networks (and the details are beyond the scope of this assignment), and the ratios are known as branching ratios. For this paper, the 6 Horton Orders are: 

1. Horton Order 1: Individuals
2. Horton Order 2: Family
3. Horton Order 3: Dispersed Groups
4. Horton Order 4: Aggregated Groups
5. Horton Order 5: Periodic aggregations
6. Horton Order 6: Population

The actual values used for each of the Horton Orders are described below.

The authors also did the analysis by splitting the data into different continents to show that these organisational structures remain robust throughout the world. 

### Binford Dataset: 
This is a well-known data repository that was compiled and published by Dr. Lewis Binford in 2001 in a book called "Constructing Frames of Reference
An Analytical Method for Archaeological Theory Building Using Ethnographic and Environmental Data Sets". It contains information about 339 Hunter-Gatherer populations across the world, compiled from various data sources (all cited). It contains a wealth of information about group sizes, locations of the groups, but also environmental data and continues to be used in high impact publications today. 


## Managing the Data:

Upon loading the data set, we see that this is a BIG data set, with a lot of information. We need to first figure out which information is useful to us. In this paper, the authors analyse group sizes at 6 different levels. Which columns contain the relevant information for each Horton order? 

It looks like: 

1. This data set does not contain information at the level of individuals (i.e. Horton order 1)
2. The column titled "famsz" gives us the group sizes at the scale of a family. This corresponds to Horton order 2. 
3. The column titled "group1" gives us the group sizes at the scale of a "dispersed group". This corresponds to Horton order 3.
4. The column titled "group2" gives us the group sizes at the scale of a "aggregated group". This corresponds to Horton order 4.
5. The column titled "group3" gives us the group sizes at the scale of a "periodic aggregations". This corresponds to Horton order 5.
6. The column titled "tlpop" gives us the total population sizes for each HG group. This corresponds to Horton order 6. 

The values above represent the group sizes, however, for our analysis, we also need the frequency of these groups which are given by: 
1. Frequency of individuals, as given by "tlpop". This is for Horton order 1. 
2. Number of families in society, given by "numfam", which represents the famsz/tlpop values. This is for Horton order 2. 
3. Number of group1 units in society, given by "numg1". It is given by tlpop/group1 and represent Horton order 3.
4.Number of group2 units in society, given by "numg2", represents the frequency of dispersed groups. It is given by tlpop/group2. This is for Horton order 4.
5. Number of group3 units in society, given by "numg3". It is given by tlpop/group3 and represents Horton Order 5. 


The documentation for these values was taken from: https://github.com/benmarwick/binford/blob/master/data-raw/LRBcodebook.txt

Let us load in the data, clean the data (if required) and check our sample sizes for each Horton order so that we are good to start replicating tables or figures. 

```{r data_cleaning1.1}
library(curl)

dat <- read.csv(curl("https://raw.githubusercontent.com/bhavya-dv/vbhavya-data-replication-assignment/main/LRB.csv"))

#not showing what the data looks like because the data set is GINORMOUS and even doing head() takes up so much space

length(dat) #There are 507 data points. 

# But this means that there are multiple columns of the same group.  
# Does this matter for our analysis? Yes, because we will be using the geometric mean to summarize the data, rather than arithmetic mean, we must make sure that are sample sizes and values are correct. But let's address that problem separately for each Horton Order


# Creating a data frame with only total population sizes (HO = 6): 
population <- dat$tlpop
length(population) # our N matches the N in Table 1 of Hamilton et al., 2007!

# Creating a data frame with only "group3" (HO = 5): 
gr3 <- dat$group3
gr3 <- na.omit(gr3) 
length(gr3) #interesting, we are getting an N of 216, but Hamilton et al have an N of 213. Are there any duplicates? We will proceed with this. It is possible that Hamilton et al., 2007 removed 3 data points without mentioning it. We don't know. There is no documentation about this either. 

# Creating a data frame with only "group2" (HO = 4): 
gr2 <- dat$group2
gr2 <- na.omit(gr2) 
length(gr2) #We are getting the same N as that in table 1 of Hamilton et al., 2007
 
# Creating a data frame with only "group1" (HO = 3): 
gr1 <- dat$group1
gr1 <- na.omit(gr1) 
length(gr1) #We are getting the same N as that in table 1 of Hamilton et al., 2007

# Creating a data frame with only "famsz" (HO = 2): 
family <- dat$famsz
family <- na.omit(family) 
length(family) # 136, there are some non unique values
 #Now, We are getting the same n=102 which is not the same as that of table 1 of Hamilton et al., 2007, but we will proceed with this nonetheless.

all_groups_dat <- list(family,gr1,gr2,gr3,population) #a list comprising of all the required data.frames
```
```{r datacleanign1.2}
freq_tlpop <- dat$tlpop

numg3 <- na.omit(dat$numg3)

numg2 <- na.omit(dat$numg2)

numg1 <- na.omit(dat$numg1)

numfam <- na.omit(dat$numfam)

 #some of the sample sizes in Table 1.2 are different from what we get from these data frames. There is no information in the documentation or Hamilton., 2007 about if and which values were removed, but it is likely that some values were removed. We will proceed with sample sizes that we have for now.

all_groups_freq <- list(freq_tlpop,numfam,numg1,numg2,numg3) #a list comprising of all the required data.frames for table 1.2
```

## Data Replication: 

I perform 3 (4-ish) analyses: 
1. Table 1, which is a summary statistics table for group sizes, and group frequencies
2. Figure 2, A linear Regression between ln (group size) and Horton Order in order to calculate the slope and Branching Ratios by continents
3. Table 3. Another summary statistics table, by containing mean branching ratios and family sizes by continents
4. Bonus: Figure 1: Includes A box and Whisker Plot showing group size as a function of Horton Order. 

### Table 1 

```{r table1.1}
#creating an empty table where values can be input
table1.1 <- data.frame(matrix(NA, nrow = 6, ncol = 8))
colnames(table1.1) <- c("organisational level group size (g)", "Horton order (ω)", "sample size (n)", "ln mean <ln g>", "s.d", "geometric mean (g-bar)", "95% CI - Lower", "95% CI - upper")
table1.1[,1] <- c("individual", "family","dispersed group","aggregated group","periodic aggregation","population size")
table1.1[,2] <- 1:6
table1.1[,3] <- c("NA", 136,227,297,216,339)

#Okay, now we can start filling in this table with some summary statistics!

#filling in ln means, sd and geometric means
for (i in 1:5) {
  ln_mean <- mean(log(all_groups_dat[[i]]))
  table1.1[i+1,4] <- ln_mean
  table1.1[1,4] <- 0
  
  sd <- sd(log(all_groups_dat[[i]]))
  table1.1[i+1,5] <- sd
  table1.1[1,5] <- NA
  
  geom_mean <- exp(ln_mean)
  table1.1[i+1,6] <- geom_mean
  table1.1[1,6] <- 1
} 

table1.1 #Here, we see that the values are a little bit different that the original paper. But they don't seem different enough to warrant concern, yet. 

#Bootstrapping For CIs (ln_mean) 
for (i in 1:5) {
  set.seed(1)
  ln_dat <- log(all_groups_dat[[i]]) #We will bootstrap with this data 
  ln_mean <- mean(ln_dat)
  boots_ln_dat = ln_dat[sample(1:length(ln_dat), 1000, replace = TRUE)] #resampling with replacement. Creating 1000 samples
  mean_boots <- exp(mean(boots_ln_dat)) #geometric mean for bootsrapped values
  sd_boots <- sd(boots_ln_dat) #sd for bootsrapped values

  #lower - 95% CI
  lower_CI <- mean_boots - qnorm(1 - 0.05/2) * sd_boots #lower CI
  lower_CI
  table1.1[i+1,7] <- lower_CI
  table1.1[1,7] <- NA
  
  #upper - 95% CI
  upper_CI <- mean_boots + qnorm(1 - 0.05/2) * sd_boots #upper CI
  upper_CI
  table1.1[i+1,8] <- upper_CI
  table1.1[1,8] <- NA
}

table1.1 #The CI values actually look quite different from the values in the published table

```
```{r table1.2}
#creating an empty table where values can be input
table1.2 <- data.frame(matrix(NA, nrow = 6, ncol = 8))
colnames(table1.2) <- c("Frequency, N(g)", "Horton order (ω)", "sample size (n)", "ln mean <ln N(g)>", "s.d", "geometric mean (N(g)-bar)", "95% CI - Lower", "95% CI - upper")
table1.2[,1] <- c("individual", "family","dispersed group","aggregated group","periodic aggregation","poopulation size")
table1.2[,2] <- 1:6
table1.2[,3] <- c(339, 216, 297, 227, 128, "NA")

#Okay, now we can start filling in this table with some summary statistics!

#filling in ln means, sd and geometric means
for (i in 1:5) {
  ln_mean <- mean(log(all_groups_freq[[i]]))
  table1.2[i,4] <- ln_mean
  table1.2[6,4] <- 0
  
  sd <- sd(log(all_groups_freq[[i]]))
  table1.2[i,5] <- sd
  table1.2[6,5] <- NA
  
  geom_mean <- exp(ln_mean)
  table1.2[i,6] <- geom_mean
  table1.2[6,6] <- 1
} 

table1.2 #Here, we see that the values are a little bit different that the original paper. But they don't seem different enough to warrant concern, yet. 

#Bootstrapping For CIs (ln_mean) 
for (i in 1:5) {
  set.seed(1)
  ln_dat <- log(all_groups_freq[[i]]) #We will bootstrap with this data 
  ln_mean <- mean(ln_dat)
  boots_ln_dat = ln_dat[sample(1:length(ln_dat), 1000, replace = TRUE)] #resampling with replacement. Creating 1000 samples
  mean_boots <- exp(mean(boots_ln_dat)) #geometric mean for bootsrapped values
  sd_boots <- sd(boots_ln_dat) #sd for bootsrapped values

  #lower - 95% CI
  lower_CI <- mean_boots - qnorm(1 - 0.05/2) * sd_boots #lower CI
  lower_CI
  table1.2[i,7] <- lower_CI
  table1.2[6,7] <- NA
  
  #upper - 95% CI
  upper_CI <- mean_boots + qnorm(1 - 0.05/2) * sd_boots #upper CI
  upper_CI
  table1.2[i,8] <- upper_CI
  table1.2[6,8] <- NA
}

table1.2 #The CI values actually look quite different from the values in the published table, but that is to be expected if we bootstrap the values. 

```
### Plotting Figure 1: Group sizes as a function of Horton order (Bonus?)
```{r fig1}
library(ggplot2)
family <- as.data.frame(family)
colnames(family) <- "group_size"
fig1_df <- family
gr1 <- as.data.frame(gr1)
colnames(gr1) <- "group_size"
fig1_df <- rbind(fig1_df,gr1)
gr2 <- as.data.frame(gr2)
colnames(gr2) <- "group_size"
fig1_df <- rbind(fig1_df,gr2)
gr3 <- as.data.frame(gr3)
colnames(gr3) <- "group_size"
fig1_df <- rbind(fig1_df,gr3)
population <- as.data.frame(population)
colnames(population) <- "group_size"
fig1_df <- rbind(fig1_df,population)

fig1_df$Horton_Order <- NA
fig1_df$Horton_Order[1:102] <- 2
fig1_df$Horton_Order[103:329] <- 3
fig1_df$Horton_Order[330:626] <- 4
fig1_df$Horton_Order[627:842] <- 5
fig1_df$Horton_Order[843:1181] <- 6
ho1<- data.frame(1,1)
colnames(ho1) <- c("group_size","Horton_Order")
fig1_df<- rbind(fig1_df,ho1)
unique(fig1_df$Horton_Order)


fig1 <- ggplot(fig1_df,aes(factor(Horton_Order),group_size))+ coord_trans(y = "log10") +geom_boxplot()
fig1

#NOTE: 
#In Hamilton et al., 2007, they plot a box and whisker plot where the whiskers show 95% CIs around the median, and the boxes show 67% CIs. However, the only code that I could find that does that is: 
#fig1 <- ggplot(fig1_df,aes(factor(Horton_Order),group_size))+ coord_trans(y = "log10") 
#sd.box <- function(d) {
#return(data.frame(y = median(d), ymin=mean(d) - qnorm(1 - 0.05/2) * sd(d), ymax=mean(d) + qnorm(1 - 0.05/2) * sd(d), upper=mean(d) + qnorm(1 - 0.33/2) * sd(d), lower=mean(d) - qnorm(1 - 0.33/2) * sd(d))) }
#fig1 <- fig1 + stat_summary(fun.data = sd.box, geom="boxplot")
#fig1
#However, this code should be working, but for whatever reason, it gives an error because I haven't defined some of the aesthetics, even though it should be taking the defaults. I'm not sure how to fix this and I spent HOURS just finding this code to being with because box and whisker plots usually use quartiles.

# Source for the above code: https://github.com/tidyverse/ggplot2/issues/898
```

### Table 2: Branching Ratios and Mean Family Sizes by Continent


```{r by_continents}
#Making new data frames for each continent
data_continent <- cbind(dat$continent,dat$famsz)
asia <- data_continent[data_continent[,1] == "Asia",]
africa <- data_continent[data_continent[,1] == "Africa",]
n_am <- data_continent[data_continent[,1] == "North America",]
australia <- data_continent[data_continent[,1] == "Australia",]
s_am <- data_continent[data_continent[,1] == "South America",]

#combining all data frames by continents into a list that can be indexed and used in a function to calculate stats 
continents_dat <- list(data_continent,asia,africa,n_am,australia,s_am)
```


```{r table2}
#skeletons of table 2
table2 <- data.frame(matrix(NA, nrow = 6, ncol = 9))
colnames(table2) <- c("sample", "sample size (n)", "Branching Ratios (B-bar)", "95% CI - Lower", "95% CI - upper", "sample size (n)", "Family Size (F-bar)","95% CI - Lower", "95% CI - upper")
table2[,1] <- c("All data", "Asia","Africa","North America","Australia","South America")

for (i in 1:6) {
  sample_size_fam <- length(na.omit(continents_dat[[i]][,2]))
  table2[i,6] <- sample_size_fam
  
  set.seed(1)
  ln_dat <- log(as.numeric(na.omit(continents_dat[[i]][,2]))) #We will bootstrap with this data in a few steps and use it to calculate the geometric mean
  ln_mean <- mean(ln_dat)
  geom_mean <- exp(ln_mean)
  table2[i,7] <- geom_mean #adding geometric means to column F-bar
  
  #bootstrapping for CIs
  boots_ln_dat = ln_dat[sample(1:length(ln_dat), 1000, replace = TRUE)] #resampling with replacement. Creating 1000 samples
  mean_boots <- exp(mean(boots_ln_dat)) #geometric mean for bootsrapped values
  sd_boots <- sd(boots_ln_dat) #sd for bootsrapped values

  #lower - 95% CI
  lower_CI <- mean_boots - qnorm(1 - 0.05/2) * sd_boots #lower CI
  lower_CI
  table2[i,8] <- lower_CI
  
  #upper - 95% CI
  upper_CI <- mean_boots + qnorm(1 - 0.05/2) * sd_boots #upper CI
  upper_CI
  table2[i,9] <- upper_CI
}

table2
```

Comments so far: 

```{r continents_dat}
#Because branching rations need information about the frequencies of family size (ω = 2), and for Horton order ω-1 = 1, which is frequency of individuals, let us add that data to our "data by continent" data frame 

data_continent <- cbind(data_continent,dat$tlpop)
data_continent <- cbind(data_continent,dat$numfam)
data_continent <- cbind(data_continent,dat$numg1)
data_continent <- cbind(data_continent,dat$numg2)
data_continent <- cbind(data_continent,dat$numg3)

#re-making data frames for each continent, but now containing the new required information
asia <- data_continent[data_continent[,1] == "Asia",]
africa <- data_continent[data_continent[,1] == "Africa",]
n_am <- data_continent[data_continent[,1] == "North America",]
australia <- data_continent[data_continent[,1] == "Australia",]
s_am <- data_continent[data_continent[,1] == "South America",]

#combining all data frames by continents into a list that can be indexed and used in a function to calculate branching ratios and other stats 
continents_dat <- list(data_continent,asia,africa,n_am,australia,s_am)
```


### Figure 2: Horton Plots Per Continent

In order to fill the first four columns of Table 2, it will be useful to have the values for branching ratios. The easies way to get branching ratios is to run linear regressions for ln frequency of group size as a function of the Horton order. Once we get the slope ( λ) from these linear regressions, we can calculate branching ratios with this formula: 

  λ = lnB
  

```{r linear-reg-dat}

# In order to run a linear regression for <ln N(g)> vs Horton Order, we need to calculate <ln N(g)> values for each Horton Order in each continent. Let's create a new data frames per continent to hold these values. 

#starting with all data
linear_reg_dat <- data.frame(matrix(NA, nrow = 6, ncol = 3))
colnames(linear_reg_dat) <- c("horton_order","ln_mean_freq","Continent")
linear_reg_dat[,1] <- 1:6
linear_reg_dat[,3] <- as.factor("All")

for (i in 3:7) {
  ln_dat <- log(as.numeric(na.omit(data_continent[,i])))
  ln_mean <- mean(ln_dat)
  linear_reg_dat[i-2,2] <- ln_mean
  linear_reg_dat[6,2] <- 0
}

#For Asia
linear_reg_asia <- data.frame(matrix(NA, nrow = 6, ncol = 3))
colnames(linear_reg_asia) <- c("horton_order","ln_mean_freq","Continent")
linear_reg_asia[,1] <- 1:6
linear_reg_asia[,3] <- as.factor("Asia")

for (i in 3:7) { 
  ln_dat <- log(as.numeric(na.omit(asia[,i])))
  ln_mean <- mean(ln_dat)
  linear_reg_asia[i-2,2] <- ln_mean
  linear_reg_asia[6,2] <- 0
}

linear_reg_dat1 <- rbind(linear_reg_dat,linear_reg_asia)

#repeating the same for Africa
linear_reg_africa <- data.frame(matrix(NA, nrow = 6, ncol = 3))
colnames(linear_reg_africa) <- c("horton_order","ln_mean_freq","Continent")
linear_reg_africa[,1] <- 1:6
linear_reg_africa[,3] <- as.factor("Africa")

for (i in 3:7) {
  ln_dat <- log(as.numeric(na.omit(africa[,i])))
  ln_mean <- mean(ln_dat)
  linear_reg_africa[i-2,2] <- ln_mean
  linear_reg_africa[6,2] <- 0
}
linear_reg_dat1 <- rbind(linear_reg_dat1,linear_reg_africa)

#repeating the same for North America
linear_reg_nam <- data.frame(matrix(NA, nrow = 6, ncol = 3))
colnames(linear_reg_nam) <- c("horton_order","ln_mean_freq","Continent")
linear_reg_nam[,1] <- 1:6
linear_reg_nam[,3] <- as.factor("North America")

for (i in 3:7) {
  ln_dat <- log(as.numeric(na.omit(n_am[,i])))
  ln_mean <- mean(ln_dat)
  linear_reg_nam[i-2,2] <- ln_mean
  linear_reg_nam[6,2] <- 0
}
linear_reg_dat1 <- rbind(linear_reg_dat1,linear_reg_nam)

#repeating the same for Australia
linear_reg_aus <- data.frame(matrix(NA, nrow = 6, ncol = 3))
colnames(linear_reg_aus) <- c("horton_order","ln_mean_freq","Continent")
linear_reg_aus[,1] <- 1:6
linear_reg_aus[,3] <- as.factor("Australia")

for (i in 3:7) {
  ln_dat <- log(as.numeric(na.omit(australia[,i])))
  ln_mean <- mean(ln_dat)
  linear_reg_aus[i-2,2] <- ln_mean
  linear_reg_aus[6,2] <- 0
}

linear_reg_dat1 <- rbind(linear_reg_dat1,linear_reg_aus)

#repeating the same for South America
linear_reg_sam <- data.frame(matrix(NA, nrow = 6, ncol = 3))
colnames(linear_reg_sam) <- c("horton_order","ln_mean_freq","Continent")
linear_reg_sam[,1] <- 1:6
linear_reg_sam[,3] <- as.factor("South America")

for (i in 3:7) {
  ln_dat <- log(as.numeric(na.omit(s_am[,i])))
  ln_mean <- mean(ln_dat)
  linear_reg_sam[i-2,2] <- ln_mean
  linear_reg_sam[6,2] <- 0
}

linear_reg_dat1 <- rbind(linear_reg_dat,linear_reg_sam)

```

```{r linear_reg}

#Running linear regressions

#For all continents
linear_model <- lm(formula = ln_mean_freq ~ horton_order, data= linear_reg_dat)
summary(linear_model) 
# The equation obtained is Y = 7.77607 - 1.28403x, r-squared = 0.9934

exp(1.28) # since slope is λ, B = exp(slope)


#For Asia
linear_model <- lm(formula = ln_mean_freq ~ horton_order, data= linear_reg_asia)
summary(linear_model) 
# The equation obtained is Y = 7.35645 - 1.18977x, r-squared = 0.9893

exp(1.18977) # since slope is λ, B = exp(slope)

#For Africa
linear_model <- lm(formula = ln_mean_freq ~ horton_order, data= linear_reg_africa)
summary(linear_model) 
# The equation obtained is Y = 7.79111 - 1.22251x, r-squared = 0.9804

exp(1.22251) # since slope is λ, B = exp(slope)

#For North America
linear_model <- lm(formula = ln_mean_freq ~ horton_order, data= linear_reg_nam)
summary(linear_model) 
# The equation obtained is Y = 8.09601 - 1.34211x, r-squared = 0.9954

exp(1.34211) # since slope is λ, B = exp(slope)

#For Australia
linear_model <- lm(formula = ln_mean_freq ~ horton_order, data= linear_reg_aus)
summary(linear_model) 
# The equation obtained is Y = 7.31263 - 1.22487x, r-squared = 0.9877

exp(1.22487) # since slope is λ, B = exp(slope)

#For South America
linear_model <- lm(formula = ln_mean_freq ~ horton_order, data= linear_reg_sam)
summary(linear_model) 
# The equation obtained is Y = 6.9266 - 1.1569x, r-squared = 0.969

exp(1.1569) # since slope is λ, B = exp(slope)

#Plotting Figure 2
#we also want to add the equations and r-squared values to the graphs, we'll do that using the package gridExtra
library(gridExtra)
library(grid)
library(ggplot2)
fig2 <- ggplot(linear_reg_dat1, aes(horton_order,ln_mean_freq)) + geom_point() +
  facet_wrap(~ Continent, ncol=3)+
  geom_errorbar(aes(ymin = ln_mean_freq-sd,ymax = ln_mean_freq+sd)) + #error bars as described for fig 2 
  geom_smooth(method="lm") #figure 2, with everything except the equations (95% CI, and linear regression line)
 
grid.newpage()
vpa_ <- viewport(width = 1, height = 1)
print(fig2, vp = vpa_)
grid.text("Y = 7.77607 - 1.28403x", x=0.25, y=0.9,gp = gpar(fontsize = 8))
grid.text("r-squared = 0.9934", x=0.25, y=0.85,gp = gpar(fontsize = 8))
grid.text("Y = 7.35645 - 1.18977x", x=0.55, y=0.9,gp = gpar(fontsize = 8))
grid.text("r-squared = 0.9934", x=0.55, y=0.85,gp = gpar(fontsize = 8))
grid.text("Y = 7.79111 - 1.22251x", x=0.85, y=0.9,gp = gpar(fontsize = 8))
grid.text("r-squared = 0.9804", x=0.85, y=0.85,gp = gpar(fontsize = 8))
grid.text("Y = 8.09601 - 1.34211x", x=0.25, y=0.40,gp = gpar(fontsize = 8))
grid.text("r-squared = 0.9954", x=0.25, y=0.38,gp = gpar(fontsize = 8))
grid.text("Y = 7.31263 - 1.22487x", x=0.55, y=0.40,gp = gpar(fontsize = 8))
grid.text("r-squared = 0.9877", x=0.55, y=0.38,gp = gpar(fontsize = 8))
grid.text("Y = 6.9266 - 1.1569x", x=0.85, y=0.40,gp = gpar(fontsize = 8))
grid.text("r-squared = 0.969", x=0.85, y=0.38,gp = gpar(fontsize = 8))

#Note: When Knit, the Plots don't show up properly. I am adding another figure that I had previously gotten using THE EXACT SAME CODE. No cheating, I promise. 
```

Okay, We now have figure 2. 

![Figure 2.](Fig2.png)

But, the branching ratios have been calculated using a linear regression analysis. All the values range from 3.18 to 3.82, which show that all branchings are self-similar. To calculate more accurate branching, however, we can separately calculate 
$$B = \bar{N}(g_i^a)/\bar{N}(g_i^ω)$$

a = ω -1

Then, the mean of this for each population gives a more accurate values for branching ratios 

```{r table2_cont}

#filling up the first four columns of table 2
for (i in 1:6) {
  
  sample_size_fam <- length(na.omit(continents_dat[[i]][,3]))
  table2[i,2] <- sample_size_fam
  
linear_reg_dat$geom_mean <- exp(linear_reg_dat$ln_mean_freq) #adding geometric means
#doing this for all continents
linear_reg_asia$geom_mean <- exp(linear_reg_asia$ln_mean_freq)
linear_reg_africa$geom_mean <- exp(linear_reg_africa$ln_mean_freq)
linear_reg_nam$geom_mean <- exp(linear_reg_nam$ln_mean_freq)
linear_reg_aus$geom_mean <- exp(linear_reg_aus$ln_mean_freq)
linear_reg_sam$geom_mean <- exp(linear_reg_sam$ln_mean_freq)

linear_reg_list <- list(linear_reg_dat$geom_mean,linear_reg_asia$geom_mean,linear_reg_africa$geom_mean,linear_reg_nam$geom_mean,linear_reg_aus$geom_mean,linear_reg_sam$geom_mean)

for (i in 1:6) {
  data <- linear_reg_list[[i]]
    a <- data[1]/data[2]
    b <- data[2]/data[3]
    c <- data[3]/data[4]
    d <- data[4]/data[5]
    e <- data[5]/data[6]
    mean_branchrat <- (a+b+c+d+e)/5
    table2[i,3] <- mean_branchrat
    
    for_boots <- c(a,b,c,d,e)
    
    set.seed(100)
    boots_data = for_boots[sample(1:length(for_boots), 1000, replace = TRUE)] #re-sampling with replacement. Creating 1000 samples
   mean_boots <- mean(boots_data) #mean for bootsrapped values
   sd_boots <- sd(boots_data) #sd for bootsrapped values

  #lower - 95% CI
  lower_CI <- mean_boots - qnorm(1 - 0.05/2) * sd_boots #lower CI
  lower_CI
  table2[i,4] <- lower_CI
  
  #upper - 95% CI
  upper_CI <- mean_boots + qnorm(1 - 0.05/2) * sd_boots #upper CI
  upper_CI
  table2[i,5] <- upper_CI 
}}

table2
```


### Challenges Faced: 
1. This was a pretty hard paper to replicate (which I didn't expect). It was highly theoretical and in spite of the authors doing a decent job of explaining their methodology concisely, I felt that the theoretical nature of the paper made it hard for me to track down exactly what was happening. 
2. There was no documentation about which samples were removed, and if they were. But the sample sizes didn't end up matching. 
3. I had issues with some code. The plots didn't knit properly even though the same exact code ran fine when I did it in a R script to check my code.

Overall, it was stressful, but gratifying.

### Reference: 

Binford, L. R. (2001). Constructing Frames of Reference: An Analytical Method for Archaeological Theory Building Using Ethnographic and Environmental Data Sets. University of California Press.

Hamilton, M. J., Milne, B. T., Walker, R. S., Burger, O., & Brown, J. H. (2007). The complex structure of hunter–gatherer social networks. Proceedings of the Royal Society B: Biological Sciences, 274(1622), 2195–2203. https://doi.org/10.1098/rspb.2007.0564


