---
title: "vbhavya_data_replication"
author: "Bhavya Deepti Vadavalli"
date: "2023-12-03"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Introduction:
### About Hunter-Gatherer Social Networks: 

# Goals of the Project:

# Methodology: 
## Horton Analysis:

## Binford Dataset: 


### Managing the Data:

Upon loading the data set, we see that this is a BIG data set, with a lot of information. We need to first figure out which information is useful to us. In this paper, the authors analyse group sizes at 6 different levels. Which columns contain the relevant information for each Horton order? 

It looks like: 

1. This data set does not contain information at the level of individuals (i.e. Horton order 1)
2. The column titled "famsz" gives us the group sizes at the scale of a family. This corresponds to Horton order 2. 
3. The column titled "group1" gives us the group sizes at the scale of a "dispersed group". This corresponds to Horton order 3.
4. The column titled "group2" gives us the group sizes at the scale of a "aggregated group". This corresponds to Horton order 4.
5. The column titled "group3" gives us the group sizes at the scale of a "periodic aggregations". This corresponds to Horton order 5.
6. The column titled "tlpop" gives us the total population sizes for each HG group. This corresponds to Horton order 6. 

The values above represent the group sizes, however, for our analysis, we also need the frequency of these groups which are given by: 
1. Frequency of individuals, as given by "tlpop". This is for Horton order 1. 
2. Number of families in society, given by "numfam", which represents the famsz/tlpop values. This is for Horton order 2. 
3. Number of group1 units in society, given by "numg1". It is given by tlpop/group1 and represent Horton order 3.
4.Number of group2 units in society, given by "numg2", represents the frequency of dispersed groups. It is given by tlpop/group2. This is for Horton order 4.
5. Number of group3 units in society, given by "numg3". It is given by tlpop/group3 and represents Horton Order 5. 


The documentation for these values was taken from: https://github.com/benmarwick/binford/blob/master/data-raw/LRBcodebook.txt

Let us load in the data, clean the data (if required) and check our sample sizes for each Horton order so that we are good to start replicating tables or figures. 

```{r data_cleaning1.1}
library(curl)

dat <- read.csv(curl("https://raw.githubusercontent.com/bhavya-dv/vbhavya-data-replication-assignment/main/LRB.csv"))

#not showing what the data looks like because the data set is GINORMOUS and even doing head() takes up so much space

length(dat) #There are 507 data points. 

# But this means that there are multiple columns of the same group.  
# Does this matter for our analysis? Yes, because we will be using the geometric mean to summarize the data, rather than arithmetic mean, we must make sure that are sample sizes and values are correct. But let's address that problem separately for each Horton Order


# Creating a data frame with only total population sizes (HO = 6): 
population <- dat$tlpop
length(population) # our N matches the N in Table 1 of Hamilton et al., 2007!

# Creating a data frame with only "group3" (HO = 5): 
gr3 <- dat$group3
gr3 <- na.omit(gr3) 
length(gr3) #interesting, we are getting an N of 216, but Hamilton et al have an N of 213. Are there any duplicates? We will proceed with this. It is possible that Hamilton et al., 2007 removed 3 data points without mentioning it. We don't know. There is no documentation about this either. 

# Creating a data frame with only "group2" (HO = 4): 
gr2 <- dat$group2
gr2 <- na.omit(gr2) 
length(gr2) #We are getting the same N as that in table 1 of Hamilton et al., 2007
 
# Creating a data frame with only "group1" (HO = 3): 
gr1 <- dat$group1
gr1 <- na.omit(gr1) 
length(gr1) #We are getting the same N as that in table 1 of Hamilton et al., 2007

# Creating a data frame with only "famsz" (HO = 2): 
family <- dat$famsz
family <- na.omit(family) 
length(family) # 136, there are some non unique values
 #Now, We are getting the same n=102 which is not the same as that of table 1 of Hamilton et al., 2007, but we will proceed with this nonetheless.

all_groups_dat <- list(family,gr1,gr2,gr3,population) #a list comprising of all the required data.frames
```
```{r datacleanign1.2}
freq_tlpop <- dat$tlpop

numg3 <- na.omit(dat$numg3)

numg2 <- na.omit(dat$numg2)

numg1 <- na.omit(dat$numg1)

numfam <- na.omit(dat$numfam)

 #some of the sample sizes in Table 1.2 are different from what we get from these data frames. There is no information in the documentation or Hamilton., 2007 about if and which values were removed, but it is likely that some values were removed. We will proceed with sample sizes that we have for now.

all_groups_freq <- list(freq_tlpop,numfam,numg1,numg2,numg3) #a list comprising of all the required data.frames for table 1.2
```


### Table 1 

```{r table1.1}
#creating an empty table where values can be input
table1.1 <- data.frame(matrix(NA, nrow = 6, ncol = 8))
colnames(table1.1) <- c("organisational level group size (g)", "Horton order (ω)", "sample size (n)", "ln mean <ln g>", "s.d", "geometric mean (g-bar)", "95% CI - Lower", "95% CI - upper")
table1.1[,1] <- c("individual", "family","dispersed group","aggregated group","periodic aggregation","population size")
table1.1[,2] <- 1:6
table1.1[,3] <- c("NA", 136,227,297,216,339)

#Okay, now we can start filling in this table with some summary statistics!

#filling in ln means, sd and geometric means
for (i in 1:5) {
  ln_mean <- mean(log(all_groups_dat[[i]]))
  table1.1[i+1,4] <- ln_mean
  table1.1[1,4] <- 0
  
  sd <- sd(log(all_groups_dat[[i]]))
  table1.1[i+1,5] <- sd
  table1.1[1,5] <- NA
  
  geom_mean <- exp(ln_mean)
  table1.1[i+1,6] <- geom_mean
  table1.1[1,6] <- 1
} 

table1.1 #Here, we see that the values are a little bit different that the original paper. But they don't seem different enough to warrant concern, yet. 

#Bootstrapping For CIs (ln_mean) 
for (i in 1:5) {
  set.seed(1)
  ln_dat <- log(all_groups_dat[[i]]) #We will bootstrap with this data 
  ln_mean <- mean(ln_dat)
  boots_ln_dat = ln_dat[sample(1:length(ln_dat), 1000, replace = TRUE)] #resampling with replacement. Creating 1000 samples
  mean_boots <- exp(mean(boots_ln_dat)) #geometric mean for bootsrapped values
  sd_boots <- sd(boots_ln_dat) #sd for bootsrapped values

  #lower - 95% CI
  lower_CI <- mean_boots - qnorm(1 - 0.05/2) * sd_boots #lower CI
  lower_CI
  table1.1[i+1,7] <- lower_CI
  table1.1[1,7] <- NA
  
  #upper - 95% CI
  upper_CI <- mean_boots + qnorm(1 - 0.05/2) * sd_boots #upper CI
  upper_CI
  table1.1[i+1,8] <- upper_CI
  table1.1[1,8] <- NA
}

table1.1 #The CI values actually look quite different from the values in the published table

```
```{r table1.2}
#creating an empty table where values can be input
table1.2 <- data.frame(matrix(NA, nrow = 6, ncol = 8))
colnames(table1.2) <- c("Frequency, N(g)", "Horton order (ω)", "sample size (n)", "ln mean <ln N(g)>", "s.d", "geometric mean (N(g)-bar)", "95% CI - Lower", "95% CI - upper")
table1.2[,1] <- c("individual", "family","dispersed group","aggregated group","periodic aggregation","poopulation size")
table1.2[,2] <- 1:6
table1.2[,3] <- c(339, 216, 297, 227, 128, "NA")

#Okay, now we can start filling in this table with some summary statistics!

#filling in ln means, sd and geometric means
for (i in 1:5) {
  ln_mean <- mean(log(all_groups_freq[[i]]))
  table1.2[i,4] <- ln_mean
  table1.2[6,4] <- 0
  
  sd <- sd(log(all_groups_freq[[i]]))
  table1.2[i,5] <- sd
  table1.2[6,5] <- NA
  
  geom_mean <- exp(ln_mean)
  table1.2[i,6] <- geom_mean
  table1.2[6,6] <- 1
} 

table1.2 #Here, we see that the values are a little bit different that the original paper. But they don't seem different enough to warrant concern, yet. 

#Bootstrapping For CIs (ln_mean) 
for (i in 1:5) {
  set.seed(1)
  ln_dat <- log(all_groups_freq[[i]]) #We will bootstrap with this data 
  ln_mean <- mean(ln_dat)
  boots_ln_dat = ln_dat[sample(1:length(ln_dat), 1000, replace = TRUE)] #resampling with replacement. Creating 1000 samples
  mean_boots <- exp(mean(boots_ln_dat)) #geometric mean for bootsrapped values
  sd_boots <- sd(boots_ln_dat) #sd for bootsrapped values

  #lower - 95% CI
  lower_CI <- mean_boots - qnorm(1 - 0.05/2) * sd_boots #lower CI
  lower_CI
  table1.2[i,7] <- lower_CI
  table1.2[6,7] <- NA
  
  #upper - 95% CI
  upper_CI <- mean_boots + qnorm(1 - 0.05/2) * sd_boots #upper CI
  upper_CI
  table1.2[i,8] <- upper_CI
  table1.2[6,8] <- NA
}

table1.2 #The CI values actually look quite different from the values in the published table, but that is to be expected if we bootstrap the values. 

```
### Plotting Figure 1: Group sizes as a function of Horton order
```{r fig1}
library(ggplot2)
family <- as.data.frame(family)
colnames(family) <- "group_size"
fig1_df <- family
gr1 <- as.data.frame(gr1)
colnames(gr1) <- "group_size"
fig1_df <- rbind(fig1_df,gr1)
gr2 <- as.data.frame(gr2)
colnames(gr2) <- "group_size"
fig1_df <- rbind(fig1_df,gr2)
gr3 <- as.data.frame(gr3)
colnames(gr3) <- "group_size"
fig1_df <- rbind(fig1_df,gr3)
population <- as.data.frame(population)
colnames(population) <- "group_size"
fig1_df <- rbind(fig1_df,population)

fig1_df$Horton_Order <- NA
fig1_df$Horton_Order[1:102] <- 2
fig1_df$Horton_Order[103:329] <- 3
fig1_df$Horton_Order[330:626] <- 4
fig1_df$Horton_Order[627:842] <- 5
fig1_df$Horton_Order[843:1181] <- 6
ho1<- data.frame(1,1)
colnames(ho1) <- c("group_size","Horton_Order")
fig1_df<- rbind(fig1_df,ho1)
unique(fig1_df$Horton_Order)


fig1 <- ggplot(fig1_df,aes(Horton_Order,group_size, by = factor(Horton_Order)))+ geom_boxplot() + coord_trans(y = "log10")+ stat_boxplot()
fig1             
```

### Table 2: Branching Ratios and Mean Family Sizes by Continent


```{r by_continents}
#Making new data frames for each continent
data_continent <- cbind(dat$continent,dat$famsz)
asia <- data_continent[data_continent[,1] == "Asia",]
africa <- data_continent[data_continent[,1] == "Africa",]
n_am <- data_continent[data_continent[,1] == "North America",]
australia <- data_continent[data_continent[,1] == "Australia",]
s_am <- data_continent[data_continent[,1] == "South America",]

#combining all data frames by continents into a list that can be indexed and used in a function to calculate stats 
continents_dat <- list(data_continent,asia,africa,n_am,australia,s_am)
```


```{r table2}
#skeletons of table 2
table2 <- data.frame(matrix(NA, nrow = 6, ncol = 9))
colnames(table2) <- c("sample", "sample size (n)", "Branching Ratios (B-bar)", "95% CI - Lower", "95% CI - upper", "sample size (n)", "Family Size (F-bar)","95% CI - Lower", "95% CI - upper")
table2[,1] <- c("All data", "Asia","Africa","North America","Australia","South America")

for (i in 1:6) {
  sample_size_fam <- length(na.omit(continents_dat[[i]][,2]))
  table2[i,6] <- sample_size_fam
  
  set.seed(1)
  ln_dat <- log(as.numeric(na.omit(continents_dat[[i]][,2]))) #We will bootstrap with this data in a few steps and use it to calculate the geometric mean
  ln_mean <- mean(ln_dat)
  geom_mean <- exp(ln_mean)
  table2[i,7] <- geom_mean #adding geometric means to column F-bar
  
  #bootstrapping for CIs
  boots_ln_dat = ln_dat[sample(1:length(ln_dat), 1000, replace = TRUE)] #resampling with replacement. Creating 1000 samples
  mean_boots <- exp(mean(boots_ln_dat)) #geometric mean for bootsrapped values
  sd_boots <- sd(boots_ln_dat) #sd for bootsrapped values

  #lower - 95% CI
  lower_CI <- mean_boots - qnorm(1 - 0.05/2) * sd_boots #lower CI
  lower_CI
  table2[i,8] <- lower_CI
  
  #upper - 95% CI
  upper_CI <- mean_boots + qnorm(1 - 0.05/2) * sd_boots #upper CI
  upper_CI
  table2[i,9] <- upper_CI
}

table2
```

Comments so far: 

```{r continents_dat}
#Because branching rations need information about the frequencies of family size (ω = 2), and for Horton order ω-1 = 1, which is frequency of individuals, let us add that data to our "data by continent" data frame 

data_continent <- cbind(data_continent,dat$tlpop)
data_continent <- cbind(data_continent,dat$numfam)
data_continent <- cbind(data_continent,dat$numg1)
data_continent <- cbind(data_continent,dat$numg2)
data_continent <- cbind(data_continent,dat$numg3)

#re-making data frames for each continent, but now containing the new required information
asia <- data_continent[data_continent[,1] == "Asia",]
africa <- data_continent[data_continent[,1] == "Africa",]
n_am <- data_continent[data_continent[,1] == "North America",]
australia <- data_continent[data_continent[,1] == "Australia",]
s_am <- data_continent[data_continent[,1] == "South America",]

#combining all data frames by continents into a list that can be indexed and used in a function to calculate branching ratios and other stats 
continents_dat <- list(data_continent,asia,africa,n_am,australia,s_am)
```


### Figure 2: Horton Plots Per Continent

In order to fill the first four columns of Table 2, it will be useful to have the values for branching ratios. The easies way to get branching ratios is to run linear regressions for ln frequency of group size as a function of the Horton order. Once we get the slope ( λ) from these linear regressions, we can calculate branching ratios with this formula: 

  λ = lnB
  
```{r linear-reg-dat}

# In order to run a linear regression for <ln N(g)> vs Horton Order, we need to calculate <ln N(g)> values for each Horton Order in each continent. Let's create a new data frames per continent to hold these values. 

#starting with all data
linear_reg_dat <- data.frame(matrix(NA, nrow = 6, ncol = 3))
colnames(linear_reg_dat) <- c("horton_order","ln_mean_freq","Continent")
linear_reg_dat[,1] <- 1:6
linear_reg_dat[,3] <- as.factor("All")

for (i in 3:7) {
  ln_dat <- log(as.numeric(na.omit(data_continent[,i])))
  ln_mean <- mean(ln_dat)
  linear_reg_dat[i-2,2] <- ln_mean
  linear_reg_dat[6,2] <- 0
}

#For Asia
linear_reg_asia <- data.frame(matrix(NA, nrow = 6, ncol = 3))
colnames(linear_reg_asia) <- c("horton_order","ln_mean_freq","Continent")
linear_reg_asia[,1] <- 1:6
linear_reg_asia[,3] <- as.factor("Asia")

for (i in 3:7) { 
  ln_dat <- log(as.numeric(na.omit(asia[,i])))
  ln_mean <- mean(ln_dat)
  linear_reg_asia[i-2,2] <- ln_mean
  linear_reg_asia[6,2] <- 0
}

linear_reg_dat1 <- rbind(linear_reg_dat,linear_reg_asia)

#repeating the same for Africa
linear_reg_africa <- data.frame(matrix(NA, nrow = 6, ncol = 3))
colnames(linear_reg_africa) <- c("horton_order","ln_mean_freq","Continent")
linear_reg_africa[,1] <- 1:6
linear_reg_africa[,3] <- as.factor("Africa")

for (i in 3:7) {
  ln_dat <- log(as.numeric(na.omit(africa[,i])))
  ln_mean <- mean(ln_dat)
  linear_reg_africa[i-2,2] <- ln_mean
  linear_reg_africa[6,2] <- 0
}
linear_reg_dat1 <- rbind(linear_reg_dat,linear_reg_africa)

#repeating the same for North America
linear_reg_nam <- data.frame(matrix(NA, nrow = 6, ncol = 3))
colnames(linear_reg_nam) <- c("horton_order","ln_mean_freq","Continent")
linear_reg_nam[,1] <- 1:6
linear_reg_nam[,3] <- as.factor("North America")

for (i in 3:7) {
  ln_dat <- log(as.numeric(na.omit(n_am[,i])))
  ln_mean <- mean(ln_dat)
  linear_reg_nam[i-2,2] <- ln_mean
  linear_reg_nam[6,2] <- 0
}
linear_reg_dat1 <- rbind(linear_reg_dat,linear_reg_nam)

#repeating the same for Australia
linear_reg_aus <- data.frame(matrix(NA, nrow = 6, ncol = 3))
colnames(linear_reg_aus) <- c("horton_order","ln_mean_freq","Continent")
linear_reg_aus[,1] <- 1:6
linear_reg_aus[,3] <- as.factor("Australia")

for (i in 3:7) {
  ln_dat <- log(as.numeric(na.omit(australia[,i])))
  ln_mean <- mean(ln_dat)
  linear_reg_aus[i-2,2] <- ln_mean
  linear_reg_aus[6,2] <- 0
}

linear_reg_dat1 <- rbind(linear_reg_dat,linear_reg_aus)

#repeating the same for South America
linear_reg_sam <- data.frame(matrix(NA, nrow = 6, ncol = 3))
colnames(linear_reg_sam) <- c("horton_order","ln_mean_freq","Continent")
linear_reg_sam[,1] <- 1:6
linear_reg_sam[,3] <- as.factor("South America")

for (i in 3:7) {
  ln_dat <- log(as.numeric(na.omit(s_am[,i])))
  ln_mean <- mean(ln_dat)
  linear_reg_sam[i-2,2] <- ln_mean
  linear_reg_sam[6,2] <- 0
}

linear_reg_dat1 <- rbind(linear_reg_dat,linear_reg_sam)

```

```{r linear_reg}

#Runing linear regressions

#For all continents
linear_model <- lm(formula = ln_mean_freq ~ horton_order, data= linear_reg_dat)
summary(linear_model) 
# The equation obtained is Y = 7.77607 - 1.28403x, r-squared = 0.9934

b_all<- exp(1.28) # since slope is λ, B = exp(slope)
#let's also enter this in table 2 
table2[1,3] <-b_all

#For Asia
linear_model <- lm(formula = ln_mean_freq ~ horton_order, data= linear_reg_asia)
summary(linear_model) 
# The equation obtained is Y = 7.35645 - 1.18977x, r-squared = 0.9893

b_asia<- exp(1.18977) # since slope is λ, B = exp(slope)

fig2 <- ggplot(linear_reg_dat1, aes(horton_order,ln_mean_freq)) + geom_point() +
  facet_wrap(~ Continent, ncol=3)+
  geom_errorbar(aes(ymin = ymin,ymax = ymax)) + #need to specify 1 sd
  geom_smooth(method="lm")

```


#### Introducing a new concept: Branching Ratios:

```{r table2_cont}


#filling up the first four columns of table 2
for (i in 1:6) {
  
  sample_size_fam <- length(na.omit(continents_dat[[i]][,3]))
  table2[i,2] <- sample_size_fam
}
```


### Assumptions:

### Challenges Faced: 
